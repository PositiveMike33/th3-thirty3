```mermaid
graph TD
    A[üîì HackerGPT Request] --> B{Gemini API disponible?}
    B -->|Oui| C[‚è≥ Appel Gemini 2.5 Flash]
    B -->|Non| E[üîÑ Fallback AnythingLLM]
    
    C --> D{R√©ponse < 30s?}
    D -->|Oui| F[‚úÖ R√©ponse Gemini]
    D -->|Non - Timeout| E
    
    E --> G{AnythingLLM disponible?}
    G -->|Oui| H[ü§ñ R√©ponse AnythingLLM<br/>+ Base de connaissances th3-thirty3]
    G -->|Non| I[‚ö†Ô∏è Fallback Ollama]
    
    I --> J{Ollama disponible?}
    J -->|Oui| K[üè† R√©ponse Ollama<br/>granite4:latest]
    J -->|Non| L[‚ùå Erreur - Tous backends indisponibles]
    
    F --> M[üì§ Renvoyer au chat]
    H --> M
    K --> M
    
    style F fill:#00ff00,stroke:#00aa00,color:#000
    style H fill:#ffaa00,stroke:#ff8800,color:#000
    style K fill:#ff8800,stroke:#ff4400,color:#000
    style L fill:#ff0000,stroke:#aa0000,color:#fff
    style A fill:#00d4ff,stroke:#0080ff,color:#000
```

# Architecture HackerGPT - Cascade de Fallback

## üéØ Objectif
Fournir des r√©ponses de s√©curit√© de qualit√© maximale avec une disponibilit√© garantie gr√¢ce √† une cascade intelligente de backends LLM.

## üîÑ Flux de d√©cision

### Niveau 1 : Gemini 2.5 Flash (Priorit√© maximale)
- **Avantages** :
  - Mod√®le le plus puissant et √† jour
  - Sp√©cialis√© en s√©curit√© avec le persona HackerGPT
  - Acc√®s aux derni√®res connaissances
  
- **Contraintes** :
  - N√©cessite connexion internet
  - Timeout apr√®s 30 secondes
  - D√©pendant de la disponibilit√© de l'API Google

### Niveau 2 : AnythingLLM th3-thirty3 (Fallback intelligent)
- **Avantages** :
  - Acc√®s √† la base de connaissances personnalis√©e
  - RAG avec embeddings locaux
  - Contexte projet th3-thirty3
  - Plus rapide que Gemini en cas de surcharge
  
- **Contraintes** :
  - N√©cessite AnythingLLM configur√©
  - D√©pend du mod√®le backend configur√© dans AnythingLLM

### Niveau 3 : Ollama granite4 (Dernier recours)
- **Avantages** :
  - Totalement local et offline
  - Aucune d√©pendance r√©seau
  - Toujours disponible
  
- **Contraintes** :
  - Pas d'acc√®s √† la base de connaissances
  - Qualit√© de r√©ponse moindre
  - N√©cessite ressources locales

## üìä Statistiques de performance attendues

| Backend | Temps moyen | Qualit√© | Disponibilit√© |
|---------|-------------|---------|---------------|
| Gemini 2.5 Flash | 5-15s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 98% |
| AnythingLLM th3-thirty3 | 8-20s | ‚≠ê‚≠ê‚≠ê‚≠ê | 95% |
| Ollama granite4 | 10-30s | ‚≠ê‚≠ê‚≠ê | 99.9% |

## üé® Messages utilisateur

| √âtape | Message affich√© |
|-------|----------------|
| D√©but | `‚è≥ HackerGPT analyse en cours avec Gemini... (Fallback: AnythingLLM th3-thirty3)` |
| Gemini timeout | `üîÑ Gemini lent, bascule vers AnythingLLM...` |
| AnythingLLM activ√© | `ü§ñ Utilisation de la base de connaissances th3-thirty3...` |
| Ollama activ√© | `‚ö†Ô∏è Mode local activ√© (Ollama)` |
| √âchec total | `‚ùå Tous les backends sont indisponibles` |

## üí° Recommandations

1. **Garder AnythingLLM en ligne** pour un fallback efficace
2. **Configurer un mod√®le puissant** dans AnythingLLM (GPT-4o recommand√©)
3. **Alimenter la base de connaissances** th3-thirty3 avec docs de s√©curit√©
4. **Monitorer les logs** pour identifier les patterns de fallback
